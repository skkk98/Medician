# -*- coding: utf-8 -*-
"""X-Ray_Pneumonia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sA3DarGZnmTdUlVy7jdq2hQSidXTHolo
"""

from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
import pickle
import numpy as np

import os
import pprint
import tensorflow as tf

if 'COLAB_TPU_ADDR' not in os.environ:
  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')
else:
  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']
  print ('TPU address is', tpu_address)

  with tf.Session(tpu_address) as session:
    devices = session.list_devices()
    
  print('TPU devices:')
  pprint.pprint(devices)

classifier = Sequential()

#convolution
classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))

#Pooling
classifier.add(MaxPooling2D(pool_size = (2, 2)))

#flattening
classifier.add(Flatten())

#Full Connection
classifier.add(Dense(output_dim = 128, activation = 'relu'))
classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))

#Compiling the CNN
classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

#Fitting the CNN to image
from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

val_datagen = ImageDataGenerator(rescale=1./255)

path = ""
if True:
    from google.colab import drive, files
    drive.mount('/content/drive/')
    path = "/content/drive/My Drive/chest_xray/"
training_data_dir = path + "train" # 10 000 * 2
#validation_data_dir = path + "data/validation" # 2 500 * 2
test_data_dir = path + "test" # 12 500
val_data_dir = path + "val"

training_set = train_datagen.flow_from_directory(
                                                training_data_dir,
                                                target_size=(64, 64),
                                                batch_size=32,
                                                class_mode='binary')

test_set = test_datagen.flow_from_directory(
                                            test_data_dir,
                                            target_size=(64, 64),
                                            batch_size=32,
                                            class_mode='binary')

val_set = val_datagen.flow_from_directory(
                                            val_data_dir,
                                            target_size=(64, 64),
                                            batch_size=32,
                                            class_mode='binary')

classifier.fit_generator(
                    training_set,
                    steps_per_epoch=1341,
                    epochs=2)
pkl_filename = "pickle_model.pkl"
file = open('pkl_filename', 'wb')
pickle.dump(classifier, file)

# pkl_filename = "pickle_model.pkl"
# file = open('pkl_filename', 'rb')
# data = pickle.load(file)
classifier.predict(val_set, batch_size=None, verbose=0, steps=None)